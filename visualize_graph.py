import os
import logging

# 1. 设置 Mock 环境变量，确保 build_llm 能通过配置检查
# 这些值仅用于构建图结构，不会发生真实调用
os.environ["INTENT.PROVIDER"] = "openai"
os.environ["INTENT.MODEL"] = "mock-model"
os.environ["PLANNER.PROVIDER"] = "openai"
os.environ["PLANNER.MODEL"] = "mock-model"
os.environ["AGENT.PROVIDER"] = "openai"
os.environ["AGENT.MODEL"] = "mock-model"
os.environ["REFLECTOR.PROVIDER"] = "openai"
os.environ["REFLECTOR.MODEL"] = "mock-model"

# 设置 Provider 也就是 OpenAI 的配置
os.environ["LLM.PROVIDERS.OPENAI.BASE_URL"] = "https://api.mock.com/v1"
os.environ["LLM.PROVIDERS.OPENAI.API_KEY"] = "sk-mock-key"

# 2. 导入构建函数
try:
    from llm import build_llm, build_reflection_multi_agent_graph
except ImportError as e:
    print(f"Error importing modules: {e}")
    exit(1)

def generate_mermaid():
    print("Building LangGraph...")
    try:
        # 构建 LLM 对象 (全是 Mock 的)
        intent_llm, planner_llm, agent_llm, reflector_llm, responder_llm = build_llm()
        
        # 构建图
        graph = build_reflection_multi_agent_graph(
            intent_llm, planner_llm, agent_llm, reflector_llm, responder_llm
        )
        
        # 生成 Mermaid 代码
        # xray=1 会显示子图结构（如果有）
        mermaid_code = graph.get_graph().draw_mermaid()
        
        output_file = "graph_architecture.md"
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("# LangGraph Architecture Visualization\n\n")
            f.write("Generated by `visualize_graph.py`\n\n")
            f.write("```mermaid\n")
            f.write(mermaid_code)
            f.write("\n```\n")
            
        print(f"Successfully generated Mermaid diagram to {output_file}")
        print("-" * 40)
        print(mermaid_code)
        print("-" * 40)
        
    except Exception as e:
        print(f"Failed to generate graph: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    generate_mermaid()
