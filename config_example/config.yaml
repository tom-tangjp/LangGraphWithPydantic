# LangGraph 多智能体系统配置
# 配置优先级：环境变量 > 配置文件 > 默认值

# LLM 全局默认配置（会被角色特定配置覆盖）
llm:
  # 不同 provider 的默认配置（可被环境变量覆盖）
  providers:
    qwen:
      base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
      api_key: ""
    doubao:
      base_url: "https://ark.cn-beijing.volces.com/api/v3"
      api_key: ""
    yuanbao:
      base_url: ""
      api_key: ""
    openai:
      base_url: ""
      api_key: ""
    openai_compat:
      base_url: ""
      api_key: ""
    ollama:
      base_url: "http://localhost:11435"
      api_key: ""  # Ollama 通常不需要 API key
    deepseek:
      base_url: "https://api.deepseek.com"
      api_key: ""

# 工作空间配置
workspace:
  root: "/path/to/workspace"

# 技能目录配置
skills:
  dir: "/path/to/skills/data"

# 搜索配置
search:
  backend: "searxng"

# SearXNG 搜索后端配置
searxng:
  url: "http://localhost:8080"

# 日志配置
log:
  level: "INFO"
  llm:
    content: 1  # 是否记录 LLM 调用内容

# Python 环境配置
python:
  io:
    encoding: "utf-8"

checkpointer:
  provider: "sqlite"
  db_path: "./checkpoints.sqlite"

intent:
  provider: "qwen"
  model: "qwen2-1.5b-instruct"

# planner: 规划角色
planner:
  provider: "qwen"
  model: "qwen-max"

# agent: 执行角色（researcher/solver/writer）
agent:
  provider: "qwen"
  model: "qwen-max"

researcher:
  provider: "qwen"
  model: "qwen-long"

solver:
  provider: "qwen"
  model: "qwen-turbo"

writer:
  provider: "qwen"
  model: "qwen-plus"

reflector:
  provider: "qwen"
  model: "qwen-plus"

# MCP 工具加载配置
mcp:
  # MCP server 脚本名（也可写绝对路径；若是相对路径则会拼到 scripts_dir 下）
  servers:
    ro: "my_tools.mcp_r"
    exec: "my_tools.mcp_exec_safe"
    artifacts: "my_tools.mcp_artifacts"
    net: "my_tools.mcp_net"
    shell: "my_tools.mcp_shell"
